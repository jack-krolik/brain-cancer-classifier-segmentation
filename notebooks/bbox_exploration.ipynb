{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_bbox_dataset(coco_annotations_file_path):\n",
    "    with open(coco_annotations_file_path, \"r\") as f:\n",
    "        coco_annotations = json.load(f)\n",
    "\n",
    "    # number of images\n",
    "    images_info = coco_annotations['images']\n",
    "    num_images = len(images_info)\n",
    "    print(f\"Dataset contains {num_images} images.\")\n",
    "\n",
    "    # Image sizes\n",
    "    image_sizes = {(img['height'], img['width']) for img in images_info}\n",
    "    print(f\"Dataset contains images of the following sizes: {list(image_sizes)}\")\n",
    "\n",
    "    # extracting the boundign boxes\n",
    "    bboxes = np.round(np.array([img['bbox'] for img in coco_annotations['annotations']])).astype(int)\n",
    "\n",
    "\n",
    "    for img in coco_annotations['annotations']:\n",
    "        if len(img['bbox']) != 4:\n",
    "            print(\"WTF \", len(img['bbox']))\n",
    "\n",
    "    # width distribution\n",
    "    widths = bboxes[:, 2]\n",
    "    print('\\nWidth:')\n",
    "    stats(widths, \"Width\")\n",
    "\n",
    "    # height distribution\n",
    "    heights = bboxes[:, 3]\n",
    "    print('\\nHeight:')\n",
    "    stats(heights, \"Height\")\n",
    "\n",
    "    # Area distribution\n",
    "    areas = widths * heights\n",
    "    print(\"\\nArea:\")\n",
    "    stats(areas, \"Area\")\n",
    "\n",
    "    # Width to Height Ratio\n",
    "    aspect_ratios = widths / heights\n",
    "    print(\"\\nAspect Ratio: \")\n",
    "    stats(aspect_ratios, \"Aspect Ratio\")\n",
    "\n",
    "    # Squareness\n",
    "    squareness = np.min(bboxes[:, 2:],axis=1)**2 / areas\n",
    "    print(\"\\nSquareness: \")\n",
    "    stats(squareness, 'Squareness')\n",
    "\n",
    "    # Heat map of bbox location\n",
    "    bbox_to_heat_map(bboxes, 640, 640)\n",
    "\n",
    "def stats(data, title):\n",
    "    min = np.min(data)\n",
    "    max = np.max(data)\n",
    "    mean = np.mean(data)\n",
    "    median = np.median(data)\n",
    "    var = np.var(data)\n",
    "    sd= np.std(data) \n",
    "\n",
    "    print(f'\\t- min: {np.round(min, 3)}')\n",
    "    print(f'\\t- max: {np.round(max, 3)}')\n",
    "    print(f'\\t- mean: {np.round(mean, 3)}')\n",
    "    print(f'\\t- median: {np.round(median, 3)}')\n",
    "    print(f'\\t- variance: {np.round(var, 3)}')\n",
    "    print(f'\\t- SD: {np.round(sd, 3)}')\n",
    "\n",
    "    plt.hist(data, color='b')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "          \n",
    "def bbox_to_heat_map(bbox_data, width, height):\n",
    "    num_boxes = bbox_data.shape[0]\n",
    "    heat_map = np.zeros((num_boxes, width, height))\n",
    "\n",
    "    for i in range(num_boxes):\n",
    "        x = bbox_data[i][0]\n",
    "        y = bbox_data[i][1]\n",
    "        w = bbox_data[i][2]\n",
    "        h = bbox_data[i][3]\n",
    "        heat_map[i, x:x+w, y:y+h] = 1\n",
    "\n",
    "    heat_map = np.mean(heat_map, axis=0)\n",
    "    plt.imshow(heat_map, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.title('Bounding Box Location Average')\n",
    "    plt.show()\n",
    "\n",
    "    coverage_area = heat_map.copy()\n",
    "    coverage_area[coverage_area>0] = 1\n",
    "\n",
    "    plt.imshow(coverage_area, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.title('Bounding Box Coverage')\n",
    "    plt.show()\n",
    "     \n",
    "    return heat_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coco = explore_bbox_dataset('./../datasets/tumor-segmentation/train/_annotations.coco.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorating Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_bbox_dataset('./../datasets/tumor-segmentation/validation/_annotations.coco.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_bbox_dataset('./../datasets/tumor-segmentation/test/_annotations.coco.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Anchor Boxes\n",
    "We need to ensure that all of the bounding boxes can be detected by at least 1 anchor with a sufficient IoU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.ops import box_iou\n",
    "from torch import torch\n",
    "\n",
    "def center_to_corner_box(bbox):\n",
    "    x_max = bbox[:, 0] + bbox[:, 2]\n",
    "    y_max = bbox[:, 1] + bbox[:, 3]\n",
    "    result = bbox.copy()\n",
    "    result[:, 2] = x_max\n",
    "    result[:, 3] = y_max\n",
    "    return result\n",
    "\n",
    "def generate_anchores(image_size, scales, aspect_ratios, feature_map_size):\n",
    "    anchor_boxes_centers = []  # For center coordinates\n",
    "    anchor_boxes_corners = []  # For corner coordinates\n",
    "    \n",
    "    step_size = image_size / feature_map_size  # Size of one grid cell\n",
    "    \n",
    "    for x in range(feature_map_size):\n",
    "        for y in range(feature_map_size):\n",
    "            center_x = (x + 0.5) * step_size\n",
    "            center_y = (y + 0.5) * step_size\n",
    "            \n",
    "            for scale in scales:\n",
    "                for aspect_ratio in aspect_ratios:\n",
    "                    box_height = image_size * scale / np.sqrt(aspect_ratio)\n",
    "                    box_width = image_size * scale * np.sqrt(aspect_ratio)\n",
    "                    \n",
    "                    # Center coordinates with width and height\n",
    "                    anchor_boxes_centers.append([center_x, center_y, box_width, box_height])\n",
    "                    \n",
    "                    # Convert to corner coordinates\n",
    "                    x_min = center_x - box_width / 2\n",
    "                    y_min = center_y - box_height / 2\n",
    "                    x_max = center_x + box_width / 2\n",
    "                    y_max = center_y + box_height / 2\n",
    "                    anchor_boxes_corners.append([x_min, y_min, x_max, y_max])\n",
    "    \n",
    "    return np.array(anchor_boxes_centers), np.array(anchor_boxes_corners)\n",
    "\n",
    "def analyze_anchor_boxes(bboxes_corners, anchore_corners, iou_cutoffs=[0.25, 0.5, 0.75, 0.9]):\n",
    "\n",
    "    num_boxes = bboxes_corners.shape[0]\n",
    "\n",
    "    # convert to \n",
    "    bboxes_corners = torch.tensor(bboxes_corners)\n",
    "    anchore_corners = torch.tensor(anchore_corners)\n",
    "\n",
    "    ious = box_iou(bboxes_corners, anchore_corners)\n",
    "\n",
    "    for iou_cutoff in iou_cutoffs:\n",
    "        print(f\"\\nAnalyzing cutoff IoU = {iou_cutoff}\")\n",
    "\n",
    "        positive_mask = ious >= iou_cutoff\n",
    "\n",
    "        pos_per_sample = torch.sum(positive_mask, dim=1)\n",
    "        avg_pos_per_sample = torch.mean(pos_per_sample.float()).item()\n",
    "        coverage = torch.sum(pos_per_sample > 0).item() / num_boxes\n",
    "\n",
    "        print(f\"\\t-Average Anchors Per Box: {avg_pos_per_sample}\")\n",
    "        print(f\"\\t-Ratio of Covered Boxes: {coverage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./../datasets/tumor-segmentation/test/_annotations.coco.json', \"r\") as f:\n",
    "    train_annotations = json.load(f)\n",
    "train_bboxes = np.round(np.array([img['bbox'] for img in train_annotations['annotations']])).astype(int)\n",
    "train_bboxes_corners = center_to_corner_box(train_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 640\n",
    "scales = [0.1, 0.2, 0.3]\n",
    "aspect_ratios = [1]\n",
    "feature_map_size = 20\n",
    "anchore_centers, anchor_corners = generate_anchores(image_size, scales, aspect_ratios, feature_map_size)\n",
    "\n",
    "print(f\"Anchored boxes: {len(anchore_centers)}\")\n",
    "analyze_anchor_boxes(train_bboxes_corners, anchor_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 640\n",
    "scales = [0.1, 0.2, 0.3]\n",
    "aspect_ratios = [0.66667, 1, 1.5]\n",
    "feature_map_size = 20\n",
    "anchore_centers, anchor_corners = generate_anchores(image_size, scales, aspect_ratios, feature_map_size)\n",
    "\n",
    "print(f\"Anchored boxes: {len(anchore_centers)}\")\n",
    "analyze_anchor_boxes(train_bboxes_corners, anchor_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 640\n",
    "scales = [0.1, 0.175, 0.25, 0.3]\n",
    "aspect_ratios = [1]\n",
    "feature_map_size = 20\n",
    "anchore_centers, anchor_corners = generate_anchores(image_size, scales, aspect_ratios, feature_map_size)\n",
    "\n",
    "print(f\"Anchored boxes: {len(anchore_centers)}\")\n",
    "analyze_anchor_boxes(train_bboxes_corners, anchor_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_anchor_boxes(train_bboxes_corners, anchor_corners)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
