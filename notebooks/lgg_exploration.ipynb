{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "\n",
    "root = pathlib.Path().absolute().parent\n",
    "DATASET_PATH = root / 'datasets'\n",
    "sys.path.append(str(root))\n",
    "\n",
    "from src.data.segmentation import LGGSegmentationDataset\n",
    "from src.utils.visualize import plot_images_and_masks\n",
    "from src.enums import DataSplit\n",
    "from src.utils.transforms import DualInputTransform, DualInputCompose, DualInputResize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGG Dataset Exploration\n",
    "\n",
    "Specifically looking at class inbalance...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGG_PATH = DATASET_PATH / 'lgg-mri-segmentation'\n",
    "\n",
    "train_info = pd.read_csv(LGG_PATH / 'train' / 'train.csv')\n",
    "test_info = pd.read_csv(LGG_PATH / 'test' / 'test.csv')\n",
    "\n",
    "# label 0: No-Tumor and 1: Tumor for Diagnosis Column\n",
    "train_info['Diagnosis'] = train_info['Diagnosis'].map({0: 'No-Tumor', 1: 'Tumor'})\n",
    "test_info['Diagnosis'] = test_info['Diagnosis'].map({0: 'No-Tumor', 1: 'Tumor'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = train_info['Diagnosis'].value_counts()\n",
    "test_counts = test_info['Diagnosis'].value_counts()\n",
    "\n",
    "stacks = {\n",
    "    'No-Tumor': [train_counts['No-Tumor'], test_counts['No-Tumor']],\n",
    "    'Tumor': [train_counts['Tumor'], test_counts['Tumor']]\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "width = 0.5\n",
    "\n",
    "ax.bar(['Train', 'Test'], stacks['No-Tumor'], color='orange', alpha=0.7, linewidth=2, label='No-Tumor', width=width)\n",
    "ax.bar(['Train', 'Test'], stacks['Tumor'], color='blue', alpha=0.7, linewidth=2, label='Tumor', bottom=stacks['No-Tumor'], width=width)\n",
    "ax.set_title('Diagnosis Distribution')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('Diagnosis')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = pd.DataFrame(columns=['Train', 'Test'], index=['No-Tumor', 'Tumor'], data=np.array([train_counts / train_counts.sum(), test_counts / test_counts.sum()]).T) \n",
    "\n",
    "raw = pd.DataFrame(columns=['Train', 'Test'], index=['No-Tumor', 'Tumor'], data=np.array([train_counts, test_counts]).T) \n",
    "# show df as percentage str\n",
    "distribution = distribution.map(lambda x: f'{x:.2%}')\n",
    "print(f'Distribution of Diagnosis in Train and Test Set\\n{distribution}\\n\\nRaw Counts\\n{raw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 6\n",
    "# choose N_SAMPLES random images from the train set\n",
    "tumor_samples = train_info[train_info['Diagnosis'] == 'Tumor'].sample(N_SAMPLES)['ID'].index.values\n",
    "no_tumor_samples = train_info[train_info['Diagnosis'] == 'No-Tumor'].sample(N_SAMPLES)['ID'].index.values\n",
    "\n",
    "dataset = LGGSegmentationDataset(DATASET_PATH, split=DataSplit.TRAIN, include_non_tumor=True)\n",
    "\n",
    "transformer = DualInputTransform(ToTensor())\n",
    "\n",
    "pairs_tumor = [transformer(*dataset._get_image_mask(i)) for i in tumor_samples]\n",
    "pairs_no_tumor = [transformer(*dataset._get_image_mask(i)) for i in no_tumor_samples]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Images and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_images, tumor_masks = zip(*pairs_tumor)\n",
    "\n",
    "plot_images_and_masks(tumor_images, tumor_masks, include_overlay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Images and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tumor_images, no_tumor_masks = zip(*pairs_no_tumor)\n",
    "plot_images_and_masks(no_tumor_images, no_tumor_masks, include_overlay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding distributions of pixels values across training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(loader):\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    total = 0\n",
    "\n",
    "    for images, _ in loader:\n",
    "        batch_size = images.size(0)\n",
    "        images = images.view(batch_size, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total += batch_size\n",
    "    \n",
    "    mean /= total\n",
    "    std /= total\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "transformer = DualInputCompose([\n",
    "    DualInputResize((320, 320)),\n",
    "    DualInputTransform(ToTensor()),\n",
    "\n",
    "])\n",
    "\n",
    "dataset = LGGSegmentationDataset(DATASET_PATH, split=DataSplit.TRAIN, transform=transformer)\n",
    "\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "mean, std = get_mean_std(loader)\n",
    "print(f'Mean of train dataset: {mean}')\n",
    "print(f'Std of train dataset: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
